Pipeline OCR + Search + Extraction (DMS Notebook)
==================================================

```mermaid
--- 
config: 
  layout: elk
---
flowchart TB
    A["1) Input\nImage/PDF + CLI args (lang, preprocess, tess config)"] --> B["2) Preprocess image\nPillow + optional OpenCV: grayscale, denoise, contrast, pad, rotate/OSD, threshold"]
    B --> C["3) OCR (Tesseract)\npytesseract -> OCR_TEXT"]
    C --> D["4) Language detect\nlangdetect (default fr if fail)"]
    D --> E["5) Tokenize\nspaCy fr_core_news_sm (tokenizer only)"]
    E --> F["6) Keyword classification\nkeywords loaded from classification/*.json\nscores/matched_keywords per doc_type"]
    F --> G["7) Stable decision JSON\nTHRESHOLD/MARGIN -> status OK/REVIEW\nstores doc_id/doc_type/language_hint"]
    G --> H["8) Route rules\nroute_rules loads rules/common + rules/{doc_type} + rules/templates/{template_id}"]
    G --> I["9) Layout fingerprint\nTesseract OSD + OpenCV Hough lines -> orientation/skew/table counts\ncompute template_id (hash)"]
    I --> H
    H --> J{"10) Quality gate\nOCR conf, word count, skew, density"}
    J -- REVIEW --> R["Stop / Manual review\nchunks not built, not indexed"]
    J -- OK --> K["11) Chunking\nclean text -> sliding window chunks with overlap + chunk_id"]
    K --> L["12) Corpus dedup\nsource_hash bag-of-words; skip duplicates; keep CORPUS"]
    L --> M["13) Elasticsearch index\nreset/create index doc_chunks_v1; bulk index chunks with doc_type/template_id/language_hint"]
    M --> N["14) Retrieve(query)\nES simple_query_string; filters status=OK; returns doc_id, doc_type, template_id, excerpt, text, score"]
    N --> O["15) Ask()\nregroup hits per doc -> build context"]
    O --> P["16) Apply ruleset\nextract_fields(context, ruleset) generic regex\nvalue normalizers: amount/date/phone/line_items"]
    P --> Q["17) Answer\nfields + audit(rule_id, match_raw) + sources (hits)\nstrict: keep only fields matching query triggers"]
```

Key artifacts and where they live
- classification/: required keyword lists per doc_type (JSON/YAML).
- rules/: regex extractors per type (+ common.json, optional templates/ overrides).
- test/test.ipynb: pipeline code (loading, routing, extraction, search).
- Elasticsearch: local http://127.0.0.1:9200 index doc_chunks_v1 built each run.

Routing/extraction logic
- route_rules(doc_type, template_id) merges common + type + template rules.
- extract_fields(context, ruleset) applies patterns with flags/many/use_lines, normalizes amounts (parse_number_pair), dates (ISO), phones, and line items.
- ask() picks fields matching the query (trigger words from field names/rule_id/pattern) to keep answers deterministic and auditable.
