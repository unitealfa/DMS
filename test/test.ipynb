{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b6c389",
   "metadata": {},
   "source": [
    "## Pipeline OCR (Tesseract + OpenCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d3df9",
   "metadata": {},
   "source": [
    "Langue (par défaut FR, mais bascule en EN si détecté)\n",
    "\n",
    "Par défaut, l’OCR est en français :\n",
    "\n",
    "DEFAULT_LANG = \"fra\" (côté Tesseract)\n",
    "\n",
    "spacy.load(\"fr_core_news_sm\", ...) (côté spaCy)\n",
    "\n",
    "Si tu détectes que le texte est en anglais, tu fais basculer :\n",
    "\n",
    "DEFAULT_LANG = \"eng\" (ou fra+eng si tu veux tolérer les deux)\n",
    "\n",
    "spacy.load(\"en_core_web_sm\", ...)\n",
    "\n",
    "Trucs à modifier quand tu changes de langue :\n",
    "\n",
    "la constante DEFAULT_LANG\n",
    "\n",
    "le modèle spaCy chargé (fr_core_news_sm ↔ en_core_web_sm)\n",
    "\n",
    "---\n",
    "\n",
    "Fonctionnement global du script\n",
    "\n",
    "Prendre une image (INPUT_FILE)\n",
    "\n",
    "L’améliorer via le prétraitement (gris, upscale, contraste/sharpness, seuil, etc.)\n",
    "\n",
    "Lancer Tesseract sur l’image prétraitée pour extraire le texte (OCR_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb1b1ed",
   "metadata": {},
   "source": [
    "### importation img et prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c916ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] Using INPUT_FILE=C:\\Users\\moura\\OneDrive\\Bureau\\DMS\\test\\image2tab.webp\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dependencies:\n",
    "  * Python 3.8+\n",
    "  * pytesseract\n",
    "  * pillow\n",
    "  * Tesseract binary with tessdata\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional, Tuple\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "\n",
    "try:\n",
    "    import numpy as np  # type: ignore\n",
    "except ImportError:  # pragma: no cover\n",
    "    np = None\n",
    "\n",
    "try:\n",
    "    SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # In notebooks __file__ is undefined; fall back to current working directory.\n",
    "    SCRIPT_DIR = Path.cwd()\n",
    "\n",
    "DEFAULT_LANG = \"fra\"\n",
    "DEFAULT_CONTRAST = 1.5\n",
    "DEFAULT_SHARPNESS = 1.2\n",
    "DEFAULT_BRIGHTNESS = 1.0\n",
    "DEFAULT_UPSCALE = 1.5\n",
    "DEFAULT_DPI = 300\n",
    "\n",
    "INPUT_FILE: Optional[str] = \"image2tab.webp\"\n",
    "SHOW_PREPROCESSED = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EnhanceOptions:\n",
    "    contrast: float = DEFAULT_CONTRAST\n",
    "    sharpness: float = DEFAULT_SHARPNESS\n",
    "    brightness: float = DEFAULT_BRIGHTNESS\n",
    "    upscale: float = DEFAULT_UPSCALE\n",
    "    gamma: Optional[float] = None  # gamma correction; <1 brightens darks, >1 darkens\n",
    "    pad: int = 0  # pixels to pad around the image\n",
    "    median: Optional[int] = None  # kernel size for median filter (odd int, e.g., 3)\n",
    "    unsharp_radius: Optional[float] = None  # e.g., 1.0\n",
    "    unsharp_percent: int = 150\n",
    "    invert: bool = False\n",
    "    autocontrast_cutoff: Optional[int] = None  # 0-100; percentage to clip for autocontrast\n",
    "    equalize: bool = False  # histogram equalization\n",
    "    auto_rotate: bool = False  # attempt orientation detection + rotate\n",
    "    otsu: bool = False  # auto-threshold with Otsu (requires numpy)\n",
    "    threshold: Optional[int] = None  # 0-255; if set, applies a binary threshold\n",
    "\n",
    "\n",
    "def build_config(\n",
    "    oem: Optional[int],\n",
    "    psm: Optional[int],\n",
    "    base_flags: Iterable[str],\n",
    "    dpi: Optional[int],\n",
    "    tessdata_dir: Optional[Path],\n",
    "    user_words: Optional[Path],\n",
    "    user_patterns: Optional[Path],\n",
    ") -> str:\n",
    "    parts: List[str] = []\n",
    "    if oem is not None:\n",
    "        parts.append(f\"--oem {oem}\")\n",
    "    if psm is not None:\n",
    "        parts.append(f\"--psm {psm}\")\n",
    "    if dpi is not None:\n",
    "        parts.append(f\"--dpi {dpi}\")\n",
    "    if tessdata_dir is not None:\n",
    "        parts.append(f'--tessdata-dir \"{tessdata_dir}\"')\n",
    "    if user_words is not None:\n",
    "        parts.append(f'--user-words \"{user_words}\"')\n",
    "    if user_patterns is not None:\n",
    "        parts.append(f'--user-patterns \"{user_patterns}\"')\n",
    "    parts.extend(base_flags)\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def ensure_environment(lang: str) -> None:\n",
    "    try:\n",
    "        _ = pytesseract.get_tesseract_version()\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        sys.exit(\"Tesseract binary not found on PATH. Install it and its language data.\")\n",
    "    if lang:\n",
    "        try:\n",
    "            available = set(pytesseract.get_languages(config=\"\"))\n",
    "            requested = set(lang.split(\"+\"))\n",
    "            missing = requested - available\n",
    "            if missing:\n",
    "                print(\n",
    "                    f\"Warning: missing languages: {', '.join(sorted(missing))}. \"\n",
    "                    f\"Available: {', '.join(sorted(available))}\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "        except pytesseract.TesseractError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def auto_rotate_if_needed(img: Image.Image, enhance: EnhanceOptions) -> Image.Image:\n",
    "    if not enhance.auto_rotate:\n",
    "        return img\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(img)\n",
    "        angle = None\n",
    "        for line in osd.splitlines():\n",
    "            if line.lower().startswith(\"rotate:\"):\n",
    "                try:\n",
    "                    angle = int(line.split(\":\")[1].strip())\n",
    "                except ValueError:\n",
    "                    angle = None\n",
    "                break\n",
    "        if angle is not None and angle % 360 != 0:\n",
    "            return img.rotate(-angle, expand=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_image(image: Image.Image, enhance: EnhanceOptions) -> Image.Image:\n",
    "    img = image.convert(\"L\")\n",
    "    img = auto_rotate_if_needed(img, enhance)\n",
    "\n",
    "    if enhance.invert:\n",
    "        img = ImageOps.invert(img)\n",
    "\n",
    "    if enhance.pad and enhance.pad > 0:\n",
    "        img = ImageOps.expand(img, border=enhance.pad, fill=255)\n",
    "\n",
    "    if enhance.autocontrast_cutoff is not None:\n",
    "        cutoff = max(0, min(100, enhance.autocontrast_cutoff))\n",
    "        img = ImageOps.autocontrast(img, cutoff=cutoff)\n",
    "\n",
    "    if enhance.equalize:\n",
    "        img = ImageOps.equalize(img)\n",
    "\n",
    "    if enhance.upscale and enhance.upscale != 1.0:\n",
    "        w, h = img.size\n",
    "        img = img.resize((int(w * enhance.upscale), int(h * enhance.upscale)), Image.LANCZOS)\n",
    "\n",
    "    if enhance.gamma and enhance.gamma > 0:\n",
    "        inv_gamma = 1.0 / enhance.gamma\n",
    "        lut = [pow(x / 255.0, inv_gamma) * 255 for x in range(256)]\n",
    "        img = img.point(lut)\n",
    "\n",
    "    if enhance.brightness and enhance.brightness != 1.0:\n",
    "        img = ImageEnhance.Brightness(img).enhance(enhance.brightness)\n",
    "\n",
    "    if enhance.contrast and enhance.contrast != 1.0:\n",
    "        img = ImageEnhance.Contrast(img).enhance(enhance.contrast)\n",
    "\n",
    "    if enhance.sharpness and enhance.sharpness != 1.0:\n",
    "        img = ImageEnhance.Sharpness(img).enhance(enhance.sharpness)\n",
    "\n",
    "    if enhance.unsharp_radius:\n",
    "        img = img.filter(\n",
    "            ImageFilter.UnsharpMask(\n",
    "                radius=enhance.unsharp_radius,\n",
    "                percent=enhance.unsharp_percent,\n",
    "                threshold=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if enhance.median and enhance.median > 1 and enhance.median % 2 == 1:\n",
    "        img = img.filter(ImageFilter.MedianFilter(size=enhance.median))\n",
    "\n",
    "    if enhance.threshold is not None:\n",
    "        thr = max(0, min(255, enhance.threshold))\n",
    "        img = img.point(lambda p, t=thr: 255 if p > t else 0, mode=\"1\").convert(\"L\")\n",
    "    elif enhance.otsu and np is not None:\n",
    "        arr = np.array(img, dtype=np.uint8)\n",
    "        hist, _ = np.histogram(arr, bins=256, range=(0, 256))\n",
    "        total = arr.size\n",
    "        sum_total = np.dot(np.arange(256), hist)\n",
    "\n",
    "        sum_b = 0.0\n",
    "        w_b = 0.0\n",
    "        max_var = 0.0\n",
    "        threshold = 0\n",
    "\n",
    "        for i in range(256):\n",
    "            w_b += hist[i]\n",
    "            if w_b == 0:\n",
    "                continue\n",
    "            w_f = total - w_b\n",
    "            if w_f == 0:\n",
    "                break\n",
    "            sum_b += i * hist[i]\n",
    "            m_b = sum_b / w_b\n",
    "            m_f = (sum_total - sum_b) / w_f\n",
    "            var_between = w_b * w_f * (m_b - m_f) ** 2\n",
    "            if var_between > max_var:\n",
    "                max_var = var_between\n",
    "                threshold = i\n",
    "\n",
    "        img = img.point(lambda p, t=threshold: 255 if p > t else 0, mode=\"1\").convert(\"L\")\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def parse_args(argv: Optional[Iterable[str]] = None) -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-l\", \"--lang\", default=DEFAULT_LANG)\n",
    "    parser.add_argument(\"--oem\", type=int, choices=range(0, 4), default=None)\n",
    "    parser.add_argument(\"--psm\", type=int, choices=range(0, 14), default=None)\n",
    "    parser.add_argument(\"--dpi\", type=int, default=DEFAULT_DPI)\n",
    "    parser.add_argument(\"--tessdata-dir\", type=Path, default=None)\n",
    "    parser.add_argument(\"--user-words\", type=Path, default=None)\n",
    "    parser.add_argument(\"--user-patterns\", type=Path, default=None)\n",
    "    parser.add_argument(\"--whitelist\", type=str, default=None)\n",
    "    parser.add_argument(\"--blacklist\", type=str, default=None)\n",
    "\n",
    "    parser.add_argument(\"--contrast\", type=float, default=DEFAULT_CONTRAST)\n",
    "    parser.add_argument(\"--sharpness\", type=float, default=DEFAULT_SHARPNESS)\n",
    "    parser.add_argument(\"--brightness\", type=float, default=DEFAULT_BRIGHTNESS)\n",
    "    parser.add_argument(\"--upscale\", type=float, default=DEFAULT_UPSCALE)\n",
    "    parser.add_argument(\"--gamma\", type=float, default=None)\n",
    "    parser.add_argument(\"--pad\", type=int, default=0)\n",
    "    parser.add_argument(\"--threshold\", type=int, default=None)\n",
    "    parser.add_argument(\"--median\", type=int, default=None)\n",
    "    parser.add_argument(\"--unsharp-radius\", type=float, default=None)\n",
    "    parser.add_argument(\"--unsharp-percent\", type=int, default=150)\n",
    "    parser.add_argument(\"--invert\", action=\"store_true\")\n",
    "    parser.add_argument(\"--autocontrast-cutoff\", type=int, default=None)\n",
    "    parser.add_argument(\"--equalize\", action=\"store_true\")\n",
    "    parser.add_argument(\"--auto-rotate\", action=\"store_true\")\n",
    "    parser.add_argument(\"--otsu\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        nargs=\"*\",\n",
    "        default=[],\n",
    "        metavar=\"CFG\",\n",
    "        help=\"Additional configuration flags passed verbatim to tesseract (e.g., -c foo=bar).\",\n",
    "    )\n",
    "\n",
    "    return parser.parse_args(list(argv) if argv is not None else [])\n",
    "\n",
    "\n",
    "# --------- Exécution Cellule 1 (jusqu’à l’affichage) ---------\n",
    "\n",
    "args = parse_args()\n",
    "ensure_environment(args.lang)\n",
    "\n",
    "enhance = EnhanceOptions(\n",
    "    contrast=args.contrast,\n",
    "    sharpness=args.sharpness,\n",
    "    brightness=args.brightness,\n",
    "    upscale=args.upscale,\n",
    "    gamma=args.gamma,\n",
    "    pad=args.pad,\n",
    "    median=args.median,\n",
    "    unsharp_radius=args.unsharp_radius,\n",
    "    unsharp_percent=args.unsharp_percent,\n",
    "    invert=args.invert,\n",
    "    autocontrast_cutoff=args.autocontrast_cutoff,\n",
    "    equalize=args.equalize,\n",
    "    auto_rotate=args.auto_rotate,\n",
    "    otsu=args.otsu,\n",
    "    threshold=args.threshold,\n",
    ")\n",
    "\n",
    "config_flags: List[str] = list(args.config)\n",
    "if args.whitelist:\n",
    "    config_flags.append(f\"-c tessedit_char_whitelist={args.whitelist}\")\n",
    "if args.blacklist:\n",
    "    config_flags.append(f\"-c tessedit_char_blacklist={args.blacklist}\")\n",
    "\n",
    "if not INPUT_FILE:\n",
    "    sys.exit(\"INPUT_FILE is not set. Put your image filename in INPUT_FILE.\")\n",
    "\n",
    "path = Path(INPUT_FILE)\n",
    "if not path.is_absolute():\n",
    "    path = (SCRIPT_DIR / path).resolve()\n",
    "\n",
    "if not path.exists():\n",
    "    sys.exit(f\"INPUT_FILE not found: {path}\")\n",
    "\n",
    "print(f\"[info] Using INPUT_FILE={path}\", file=sys.stderr)\n",
    "\n",
    "original = Image.open(path)\n",
    "prepped = preprocess_image(original, enhance)\n",
    "\n",
    "# Afficher les 2 images (original + prétraitée)\n",
    "original.show(title=\"original\")\n",
    "if \"SHOW_PREPROCESSED\" not in globals() or SHOW_PREPROCESSED:\n",
    "    prepped.show(title=\"preprocessed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6eeae",
   "metadata": {},
   "source": [
    "### tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9199410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTURE\n",
      "\n",
      "CODE CLENT NUMERO\n",
      "FCo0o1 4/20/2016 0002\n",
      "Ma petite entreprise CLIENT\n",
      "19,rue de place 1° mai SARL EL HANA\n",
      "16000 Alger Centre IROUTE DE BEJAIA SETIF\n",
      "Tel : 00-00-52-12- 119000\n",
      "Ident Fiscal : 160\n",
      "N°art : 160100000000\n",
      "Mode de paiement : Espèce\n",
      "Date Échéance : 5/20/2016\n",
      "Référence Description Produit Quantité P.Unitaire Valeur\n",
      "cl001 _Produit1 1000 1.00 1,000.00\n",
      "c1002 _ |Produit 2 1001 2.00 2,002.00\n",
      "c1003 _ jProduit 3 1002 3.00 3,006.00\n",
      "c1004 _ |Produit4 1003 4.00 4,012.00\n",
      "c1005 __|Produit5 1004 5.00 5,020.00\n",
      "c1006 _ |Produit 6 1005 6.00 6,030.00\n",
      "c1007 _ |Produit 7 1006 11.00 11,066.00\n",
      "c1008 Produit8 1007 118.00 118,826.00\n",
      "c1009 Produit 9 1008 19.00 19,152.00\n",
      "c1010 _ |Produit 10 1009 10.00 10,090.00\n",
      "Non assujetti à latva [Montant à payer 180,204.00\n",
      "[rimbre 1,802.00\n",
      "Montant à payer ttc 182,006.00\n",
      "\n",
      "Monatnt Facture enLettre … Cinq mille huit cent quatre vingt huit Dinars Algériens\n",
      "\n",
      "Cachet & Signature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = build_config(\n",
    "    args.oem,\n",
    "    args.psm,\n",
    "    config_flags,\n",
    "    args.dpi,\n",
    "    args.tessdata_dir,\n",
    "    args.user_words,\n",
    "    args.user_patterns,\n",
    ")\n",
    "\n",
    "OCR_TEXT = pytesseract.image_to_string(prepped, lang=args.lang, config=config)\n",
    "print(OCR_TEXT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fc794d",
   "metadata": {},
   "source": [
    "### code complet de la pipeline OCR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37d8eaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] Using INPUT_FILE=C:\\Users\\moura\\OneDrive\\Bureau\\DMS\\test\\image2tab.webp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FACTURE\n",
      "\n",
      "CODE CLENT NUMERO\n",
      "FCo0o1 4/20/2016 0002\n",
      "Ma petite entreprise CLIENT\n",
      "19,rue de place 1° mai SARL EL HANA\n",
      "16000 Alger Centre IROUTE DE BEJAIA SETIF\n",
      "Tel : 00-00-52-12- 119000\n",
      "Ident Fiscal : 160\n",
      "N°art : 160100000000\n",
      "Mode de paiement : Espèce\n",
      "Date Échéance : 5/20/2016\n",
      "Référence Description Produit Quantité P.Unitaire Valeur\n",
      "cl001 _Produit1 1000 1.00 1,000.00\n",
      "c1002 _ |Produit 2 1001 2.00 2,002.00\n",
      "c1003 _ jProduit 3 1002 3.00 3,006.00\n",
      "c1004 _ |Produit4 1003 4.00 4,012.00\n",
      "c1005 __|Produit5 1004 5.00 5,020.00\n",
      "c1006 _ |Produit 6 1005 6.00 6,030.00\n",
      "c1007 _ |Produit 7 1006 11.00 11,066.00\n",
      "c1008 Produit8 1007 118.00 118,826.00\n",
      "c1009 Produit 9 1008 19.00 19,152.00\n",
      "c1010 _ |Produit 10 1009 10.00 10,090.00\n",
      "Non assujetti à latva [Montant à payer 180,204.00\n",
      "[rimbre 1,802.00\n",
      "Montant à payer ttc 182,006.00\n",
      "\n",
      "Monatnt Facture enLettre … Cinq mille huit cent quatre vingt huit Dinars Algériens\n",
      "\n",
      "Cachet & Signature\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dependencies:\n",
    "  * Python 3.8+\n",
    "  * pytesseract\n",
    "  * pillow\n",
    "  * Tesseract binary with tessdata\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional, Tuple\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "\n",
    "try:\n",
    "    import numpy as np  # type: ignore\n",
    "except ImportError:  # pragma: no cover\n",
    "    np = None\n",
    "\n",
    "try:\n",
    "    SCRIPT_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # In notebooks __file__ is undefined; fall back to current working directory.\n",
    "    SCRIPT_DIR = Path.cwd()\n",
    "\n",
    "DEFAULT_LANG = \"fra\"\n",
    "DEFAULT_CONTRAST = 1.5\n",
    "DEFAULT_SHARPNESS = 1.2\n",
    "DEFAULT_BRIGHTNESS = 1.0\n",
    "DEFAULT_UPSCALE = 1.5\n",
    "DEFAULT_DPI = 300\n",
    "\n",
    "\n",
    "INPUT_FILE: Optional[str] = \"image2tab.webp\"\n",
    "SHOW_PREPROCESSED = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EnhanceOptions:\n",
    "    contrast: float = DEFAULT_CONTRAST\n",
    "    sharpness: float = DEFAULT_SHARPNESS\n",
    "    brightness: float = DEFAULT_BRIGHTNESS\n",
    "    upscale: float = DEFAULT_UPSCALE\n",
    "    gamma: Optional[float] = None  # gamma correction; <1 brightens darks, >1 darkens\n",
    "    pad: int = 0  # pixels to pad around the image\n",
    "    median: Optional[int] = None  # kernel size for median filter (odd int, e.g., 3)\n",
    "    unsharp_radius: Optional[float] = None  # e.g., 1.0\n",
    "    unsharp_percent: int = 150\n",
    "    invert: bool = False\n",
    "    autocontrast_cutoff: Optional[int] = None  # 0-100; percentage to clip for autocontrast\n",
    "    equalize: bool = False  # histogram equalization\n",
    "    auto_rotate: bool = False  # attempt orientation detection + rotate\n",
    "    otsu: bool = False  # auto-threshold with Otsu (requires numpy)\n",
    "    threshold: Optional[int] = None  # 0-255; if set, applies a binary threshold\n",
    "\n",
    "\n",
    "def build_config(\n",
    "    oem: Optional[int],\n",
    "    psm: Optional[int],\n",
    "    base_flags: Iterable[str],\n",
    "    dpi: Optional[int],\n",
    "    tessdata_dir: Optional[Path],\n",
    "    user_words: Optional[Path],\n",
    "    user_patterns: Optional[Path],\n",
    ") -> str:\n",
    "    parts: List[str] = []\n",
    "    if oem is not None:\n",
    "        parts.append(f\"--oem {oem}\")\n",
    "    if psm is not None:\n",
    "        parts.append(f\"--psm {psm}\")\n",
    "    if dpi is not None:\n",
    "        parts.append(f\"--dpi {dpi}\")\n",
    "    if tessdata_dir is not None:\n",
    "        parts.append(f'--tessdata-dir \"{tessdata_dir}\"')\n",
    "    if user_words is not None:\n",
    "        parts.append(f'--user-words \"{user_words}\"')\n",
    "    if user_patterns is not None:\n",
    "        parts.append(f'--user-patterns \"{user_patterns}\"')\n",
    "    parts.extend(base_flags)\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def ensure_environment(lang: str) -> None:\n",
    "    try:\n",
    "        _ = pytesseract.get_tesseract_version()\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        sys.exit(\"Tesseract binary not found on PATH. Install it and its language data.\")\n",
    "    if lang:\n",
    "        try:\n",
    "            available = set(pytesseract.get_languages(config=\"\"))\n",
    "            requested = set(lang.split(\"+\"))\n",
    "            missing = requested - available\n",
    "            if missing:\n",
    "                print(\n",
    "                    f\"Warning: missing languages: {', '.join(sorted(missing))}. \"\n",
    "                    f\"Available: {', '.join(sorted(available))}\",\n",
    "                    file=sys.stderr,\n",
    "                )\n",
    "        except pytesseract.TesseractError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def auto_rotate_if_needed(img: Image.Image, enhance: EnhanceOptions) -> Image.Image:\n",
    "    if not enhance.auto_rotate:\n",
    "        return img\n",
    "    try:\n",
    "        osd = pytesseract.image_to_osd(img)\n",
    "        angle = None\n",
    "        for line in osd.splitlines():\n",
    "            if line.lower().startswith(\"rotate:\"):\n",
    "                try:\n",
    "                    angle = int(line.split(\":\")[1].strip())\n",
    "                except ValueError:\n",
    "                    angle = None\n",
    "                break\n",
    "        if angle is not None and angle % 360 != 0:\n",
    "            return img.rotate(-angle, expand=True)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_image(image: Image.Image, enhance: EnhanceOptions) -> Image.Image:\n",
    "    img = image.convert(\"L\")\n",
    "    img = auto_rotate_if_needed(img, enhance)\n",
    "\n",
    "    if enhance.invert:\n",
    "        img = ImageOps.invert(img)\n",
    "\n",
    "    if enhance.pad and enhance.pad > 0:\n",
    "        img = ImageOps.expand(img, border=enhance.pad, fill=255)\n",
    "\n",
    "    if enhance.autocontrast_cutoff is not None:\n",
    "        cutoff = max(0, min(100, enhance.autocontrast_cutoff))\n",
    "        img = ImageOps.autocontrast(img, cutoff=cutoff)\n",
    "\n",
    "    if enhance.equalize:\n",
    "        img = ImageOps.equalize(img)\n",
    "\n",
    "    if enhance.upscale and enhance.upscale != 1.0:\n",
    "        w, h = img.size\n",
    "        img = img.resize((int(w * enhance.upscale), int(h * enhance.upscale)), Image.LANCZOS)\n",
    "\n",
    "    if enhance.gamma and enhance.gamma > 0:\n",
    "        inv_gamma = 1.0 / enhance.gamma\n",
    "        lut = [pow(x / 255.0, inv_gamma) * 255 for x in range(256)]\n",
    "        img = img.point(lut)\n",
    "\n",
    "    if enhance.brightness and enhance.brightness != 1.0:\n",
    "        img = ImageEnhance.Brightness(img).enhance(enhance.brightness)\n",
    "\n",
    "    if enhance.contrast and enhance.contrast != 1.0:\n",
    "        img = ImageEnhance.Contrast(img).enhance(enhance.contrast)\n",
    "\n",
    "    if enhance.sharpness and enhance.sharpness != 1.0:\n",
    "        img = ImageEnhance.Sharpness(img).enhance(enhance.sharpness)\n",
    "\n",
    "    if enhance.unsharp_radius:\n",
    "        img = img.filter(\n",
    "            ImageFilter.UnsharpMask(\n",
    "                radius=enhance.unsharp_radius,\n",
    "                percent=enhance.unsharp_percent,\n",
    "                threshold=0,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if enhance.median and enhance.median > 1 and enhance.median % 2 == 1:\n",
    "        img = img.filter(ImageFilter.MedianFilter(size=enhance.median))\n",
    "\n",
    "    if enhance.threshold is not None:\n",
    "        thr = max(0, min(255, enhance.threshold))\n",
    "        img = img.point(lambda p, t=thr: 255 if p > t else 0, mode=\"1\").convert(\"L\")\n",
    "    elif enhance.otsu and np is not None:\n",
    "        arr = np.array(img, dtype=np.uint8)\n",
    "        hist, _ = np.histogram(arr, bins=256, range=(0, 256))\n",
    "        total = arr.size\n",
    "        sum_total = np.dot(np.arange(256), hist)\n",
    "\n",
    "        sum_b = 0.0\n",
    "        w_b = 0.0\n",
    "        max_var = 0.0\n",
    "        threshold = 0\n",
    "\n",
    "        for i in range(256):\n",
    "            w_b += hist[i]\n",
    "            if w_b == 0:\n",
    "                continue\n",
    "            w_f = total - w_b\n",
    "            if w_f == 0:\n",
    "                break\n",
    "            sum_b += i * hist[i]\n",
    "            m_b = sum_b / w_b\n",
    "            m_f = (sum_total - sum_b) / w_f\n",
    "            var_between = w_b * w_f * (m_b - m_f) ** 2\n",
    "            if var_between > max_var:\n",
    "                max_var = var_between\n",
    "                threshold = i\n",
    "\n",
    "        img = img.point(lambda p, t=threshold: 255 if p > t else 0, mode=\"1\").convert(\"L\")\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_preprocessed_image(path: Path, enhance: EnhanceOptions) -> Image.Image:\n",
    "    image = Image.open(path)\n",
    "    return preprocess_image(image, enhance)\n",
    "\n",
    "\n",
    "def ocr_to_text(\n",
    "    path: Path,\n",
    "    lang: str,\n",
    "    oem: Optional[int],\n",
    "    psm: Optional[int],\n",
    "    config_flags: Iterable[str],\n",
    "    enhance: EnhanceOptions,\n",
    "    dpi: Optional[int],\n",
    "    tessdata_dir: Optional[Path],\n",
    "    user_words: Optional[Path],\n",
    "    user_patterns: Optional[Path],\n",
    ") -> Tuple[str, str]:\n",
    "    config = build_config(oem, psm, config_flags, dpi, tessdata_dir, user_words, user_patterns)\n",
    "    prepped = load_preprocessed_image(path, enhance)\n",
    "    text = pytesseract.image_to_string(prepped, lang=lang, config=config)\n",
    "    return text, \"pytesseract\"\n",
    "\n",
    "\n",
    "def parse_args(argv: Optional[Iterable[str]] = None) -> argparse.Namespace:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-l\", \"--lang\", default=DEFAULT_LANG)\n",
    "    parser.add_argument(\"--oem\", type=int, choices=range(0, 4), default=None)\n",
    "    parser.add_argument(\"--psm\", type=int, choices=range(0, 14), default=None)\n",
    "    parser.add_argument(\"--dpi\", type=int, default=DEFAULT_DPI)\n",
    "    parser.add_argument(\"--tessdata-dir\", type=Path, default=None)\n",
    "    parser.add_argument(\"--user-words\", type=Path, default=None)\n",
    "    parser.add_argument(\"--user-patterns\", type=Path, default=None)\n",
    "    parser.add_argument(\"--whitelist\", type=str, default=None)\n",
    "    parser.add_argument(\"--blacklist\", type=str, default=None)\n",
    "\n",
    "    parser.add_argument(\"--contrast\", type=float, default=DEFAULT_CONTRAST)\n",
    "    parser.add_argument(\"--sharpness\", type=float, default=DEFAULT_SHARPNESS)\n",
    "    parser.add_argument(\"--brightness\", type=float, default=DEFAULT_BRIGHTNESS)\n",
    "    parser.add_argument(\"--upscale\", type=float, default=DEFAULT_UPSCALE)\n",
    "    parser.add_argument(\"--gamma\", type=float, default=None)\n",
    "    parser.add_argument(\"--pad\", type=int, default=0)\n",
    "    parser.add_argument(\"--threshold\", type=int, default=None)\n",
    "    parser.add_argument(\"--median\", type=int, default=None)\n",
    "    parser.add_argument(\"--unsharp-radius\", type=float, default=None)\n",
    "    parser.add_argument(\"--unsharp-percent\", type=int, default=150)\n",
    "    parser.add_argument(\"--invert\", action=\"store_true\")\n",
    "    parser.add_argument(\"--autocontrast-cutoff\", type=int, default=None)\n",
    "    parser.add_argument(\"--equalize\", action=\"store_true\")\n",
    "    parser.add_argument(\"--auto-rotate\", action=\"store_true\")\n",
    "    parser.add_argument(\"--otsu\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--config\",\n",
    "        nargs=\"*\",\n",
    "        default=[],\n",
    "        metavar=\"CFG\",\n",
    "        help=\"Additional configuration flags passed verbatim to tesseract (e.g., -c foo=bar).\",\n",
    "    )\n",
    "\n",
    "    # Notebook safe: parse [] by default (ignores IPython args)\n",
    "    return parser.parse_args(list(argv) if argv is not None else [])\n",
    "\n",
    "\n",
    "def main(argv: Optional[Iterable[str]] = None) -> None:\n",
    "    args = parse_args(argv)\n",
    "    ensure_environment(args.lang)\n",
    "\n",
    "    enhance = EnhanceOptions(\n",
    "        contrast=args.contrast,\n",
    "        sharpness=args.sharpness,\n",
    "        brightness=args.brightness,\n",
    "        upscale=args.upscale,\n",
    "        gamma=args.gamma,\n",
    "        pad=args.pad,\n",
    "        median=args.median,\n",
    "        unsharp_radius=args.unsharp_radius,\n",
    "        unsharp_percent=args.unsharp_percent,\n",
    "        invert=args.invert,\n",
    "        autocontrast_cutoff=args.autocontrast_cutoff,\n",
    "        equalize=args.equalize,\n",
    "        auto_rotate=args.auto_rotate,\n",
    "        otsu=args.otsu,\n",
    "        threshold=args.threshold,\n",
    "    )\n",
    "\n",
    "    config_flags: List[str] = list(args.config)\n",
    "    if args.whitelist:\n",
    "        config_flags.append(f\"-c tessedit_char_whitelist={args.whitelist}\")\n",
    "    if args.blacklist:\n",
    "        config_flags.append(f\"-c tessedit_char_blacklist={args.blacklist}\")\n",
    "\n",
    "    if not INPUT_FILE:\n",
    "        sys.exit(\"INPUT_FILE is not set. Put your image filename in INPUT_FILE.\")\n",
    "\n",
    "    path = Path(INPUT_FILE)\n",
    "    if not path.is_absolute():\n",
    "        path = (SCRIPT_DIR / path).resolve()\n",
    "\n",
    "    if not path.exists():\n",
    "        sys.exit(f\"INPUT_FILE not found: {path}\")\n",
    "\n",
    "    print(f\"[info] Using INPUT_FILE={path}\", file=sys.stderr)\n",
    "\n",
    "    # 1) Ouvrir l'image originale\n",
    "    original = Image.open(path)\n",
    "\n",
    "    # 2) Appliquer le prétraitement\n",
    "    prepped = preprocess_image(original, enhance)\n",
    "\n",
    "    # 3) Afficher l'image prétraitée\n",
    "    if \"SHOW_PREPROCESSED\" not in globals() or SHOW_PREPROCESSED:\n",
    "        prepped.show(title=\"preprocessed\")\n",
    "\n",
    "    # 4) OCR sur l'image prétraitée\n",
    "    config = build_config(\n",
    "        args.oem,\n",
    "        args.psm,\n",
    "        config_flags,\n",
    "        args.dpi,\n",
    "        args.tessdata_dir,\n",
    "        args.user_words,\n",
    "        args.user_patterns,\n",
    "    )\n",
    "    global OCR_TEXT\n",
    "    OCR_TEXT = pytesseract.image_to_string(prepped, lang=args.lang, config=config)\n",
    "\n",
    "    # 5) Print du texte OCR\n",
    "    print(OCR_TEXT)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c33836",
   "metadata": {},
   "source": [
    "### Pipeline SpaCy de base & Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab1b445",
   "metadata": {},
   "source": [
    "modifer pour la langue :fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf1730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Phrase : FACTURE\n",
      "\n",
      "CODE CLENT NUMERO\n",
      "Fcoo1 4/20/2016 0002\n",
      "Ma petite entreprise CLIENT\n",
      "19, rue de place 1° mai ISARL EL HANA\n",
      "16000 Alger Centre IROUTE DE BEJAIA SETIF\n",
      "Tel : 00-00-52-12- 119000\n",
      "Ident Fiscal : 160\n",
      "N°Art : 16010000000\n",
      "Mode de paiement : Espéce\n",
      "Date Echéance : 5/20/2016\n",
      "Référence Description Produit Quantité P.Unitaire Valeur\n",
      "1001 _—‘[Produit 1 1000 1.00 1,000.00\n",
      "c1002 [Produit 2 1001 2.00 2,002.00\n",
      "c1003 [Produit 3 1002 3.00 3,006.00\n",
      "1004 _—s [Produit 4 1003 4.00 4,012.00\n",
      "c1005__—[ProduitS 1004 5.00 5,020.00\n",
      "c1006 [Produit 6 1005 6.00 6,030.00\n",
      "1007 _—‘[Produit 7 1006 11.00 11,066.00\n",
      "1008 = (Produit 8 1007 118.00 118,826.00\n",
      "1009 Produit 9 1008 19.00 19,152.00\n",
      "c1010__—‘[Produit 10 1009 10.00 10,090.00\n",
      "Non assujetti dlatva [Montant a payer 180,204.00\n",
      "\\Timbre 1,802.00\n",
      "IMontant a payer ttc 182,006.00\n",
      "\n",
      "Monatnt Facture en Lettre = Cinq mille huit cent quatre vingt huit Dinars Algériens\n",
      "\n",
      "Cachet & Signature\n",
      "Langue : fr\n",
      "Tokens : ['FACTURE', '\\n\\n', 'CODE', 'CLENT', 'NUMERO', '\\n', 'Fcoo1', '4/20/2016', '0002', '\\n', 'Ma', 'petite', 'entreprise', 'CLIENT', '\\n', '19', ',', 'rue', 'de', 'place', '1', '°', 'mai', 'ISARL', 'EL', 'HANA', '\\n', '16000', 'Alger', 'Centre', 'IROUTE', 'DE', 'BEJAIA', 'SETIF', '\\n', 'Tel', ':', '00', '-', '00', '-', '52', '-', '12-', '119000', '\\n', 'Ident', 'Fiscal', ':', '160', '\\n', 'N', '°', 'Art', ':', '16010000000', '\\n', 'Mode', 'de', 'paiement', ':', 'Espéce', '\\n', 'Date', 'Echéance', ':', '5/20/2016', '\\n', 'Référence', 'Description', 'Produit', 'Quantité', 'P.Unitaire', 'Valeur', '\\n', '1001', '_', '—', '‘', '[', 'Produit', '1', '1000', '1.00', '1,000.00', '\\n', 'c1002', '[', 'Produit', '2', '1001', '2.00', '2,002.00', '\\n', 'c1003', '[', 'Produit', '3', '1002', '3.00', '3,006.00', '\\n', '1004', '_', '—', 's', '[', 'Produit', '4', '1003', '4.00', '4,012.00', '\\n', 'c1005__—[ProduitS', '1004', '5.00', '5,020.00', '\\n', 'c1006', '[', 'Produit', '6', '1005', '6.00', '6,030.00', '\\n', '1007', '_', '—', '‘', '[', 'Produit', '7', '1006', '11.00', '11,066.00', '\\n', '1008', '=', '(', 'Produit', '8', '1007', '118.00', '118,826.00', '\\n', '1009', 'Produit', '9', '1008', '19.00', '19,152.00', '\\n', 'c1010__—‘[Produit', '10', '1009', '10.00', '10,090.00', '\\n', 'Non', 'assujetti', 'dlatva', '[', 'Montant', 'a', 'payer', '180,204.00', '\\n', '\\\\Timbre', '1,802.00', '\\n', 'IMontant', 'a', 'payer', 'ttc', '182,006.00', '\\n\\n', 'Monatnt', 'Facture', 'en', 'Lettre', '=', 'Cinq', 'mille', 'huit', 'cent', 'quatre', 'vingt', 'huit', 'Dinars', 'Algériens', '\\n\\n', 'Cachet', '&', 'Signature']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "\n",
    "texte = OCR_TEXT\n",
    "\n",
    "# 1) détecter la langue sur un gros extrait (plus stable et plus rapide)\n",
    "sample = texte[:2000]  \n",
    "try:\n",
    "    doc_lang = detect(sample)\n",
    "except:\n",
    "    doc_lang = \"fr\"  # si probleme avec detection de langue (on forcer fr)\n",
    " \n",
    "# 2) charger UN seul modèle\n",
    "nlp = spacy.load(\"fr_core_news_sm\", disable=[\"parser\", \"tagger\", \"ner\", \"lemmatizer\"])\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"ner\", \"lemmatizer\"])\n",
    "\n",
    "# 3) split phrases rapide\n",
    "sent_split = re.compile(r'(?<=[.!?])\\s+')\n",
    "\n",
    "for phrase in sent_split.split(texte):\n",
    "    phrase = phrase.strip()\n",
    "    if len(phrase) < 20:\n",
    "        continue\n",
    "\n",
    "    # tokenisation spaCy (mais pipeline ultra léger)\n",
    "    doc = nlp.make_doc(phrase)\n",
    "    print(\"\\nPhrase :\", phrase)\n",
    "    print(\"Langue :\", doc_lang)\n",
    "    print(\"Tokens :\", [t.text for t in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae6df1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c38b5574",
   "metadata": {},
   "source": [
    "## Schéma de BDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3da0aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"mmd-87e775658fb348b8a74d39591f97caae\" class=\"mermaid\">\n",
       "%%{init: {\"theme\": \"redux-dark-color\", \"layout\": \"elk\"} }%%\n",
       "erDiagram\n",
       "    ROLES {\n",
       "        INT id PK\n",
       "        VARCHAR name\n",
       "    }\n",
       "\n",
       "    USERS {\n",
       "        INT id PK\n",
       "        VARCHAR username\n",
       "        VARCHAR email\n",
       "        VARCHAR password_hash\n",
       "        INT role_id FK\n",
       "        DATETIME created_at\n",
       "    }\n",
       "\n",
       "    DOMAINS {\n",
       "        INT id PK\n",
       "        VARCHAR name\n",
       "    }\n",
       "\n",
       "    RULE_CONFIGS {\n",
       "        INT id PK\n",
       "        INT domain_id FK\n",
       "        VARCHAR version_label_Regex\n",
       "        JSONB Regex_json\n",
       "        INT created_by FK\n",
       "        DATETIME created_at\n",
       "        BOOLEAN is_active\n",
       "    }\n",
       "\n",
       "    %% Nouvelle table: \"API\" = profil/config par domaine (langue, règles, paramètres)\n",
       "    APIS {\n",
       "        INT id PK\n",
       "        INT domain_id FK\n",
       "        INT rule_config_id FK\n",
       "        VARCHAR name\n",
       "        VARCHAR language_code          \n",
       "        JSONB settings_json           \n",
       "        BOOLEAN is_active\n",
       "        INT created_by FK\n",
       "        DATETIME created_at\n",
       "    }\n",
       "\n",
       "    %% Clés par API (une API/profil peut avoir plusieurs clés d'accès)\n",
       "    API_KEYS {\n",
       "        INT id PK\n",
       "        INT api_id FK\n",
       "        VARCHAR key_hash              \n",
       "        JSONB scopes                  \n",
       "        DATETIME created_at\n",
       "        DATETIME last_used_at\n",
       "        DATETIME expires_at\n",
       "        DATETIME revoked_at\n",
       "    }\n",
       "\n",
       "    DOCUMENTS {\n",
       "        UUID id PK\n",
       "        VARCHAR filename\n",
       "        INT domain_id FK\n",
       "        VARCHAR status\n",
       "        VARCHAR empreinte_numerique\n",
       "        DATETIME uploaded_at\n",
       "        INT uploaded_by FK\n",
       "        INT api_id FK                 \n",
       "    }\n",
       "\n",
       "    FILE_STORAGE {\n",
       "        INT id PK\n",
       "        UUID document_id FK\n",
       "        VARCHAR object_path\n",
       "        INT size\n",
       "        VARCHAR empreinte_numerique\n",
       "        DATETIME stored_at\n",
       "    }\n",
       "\n",
       "    EXTRACTIONS {\n",
       "        INT id PK\n",
       "        UUID document_id FK\n",
       "        INT rule_config_id FK\n",
       "        VARCHAR field_name\n",
       "        TEXT extracted_value\n",
       "        JSONB coordinates\n",
       "        BOOLEAN is_valid\n",
       "        BOOLEAN is_overridden\n",
       "        INT overridden_by FK\n",
       "        DATETIME overridden_at\n",
       "    }\n",
       "\n",
       "    QUALITY_GATE_LOGS {\n",
       "        INT id PK\n",
       "        UUID document_id FK\n",
       "        BOOLEAN is_passed\n",
       "        TEXT failure_reason\n",
       "        DATETIME checked_at\n",
       "        VARCHAR check_origin          \n",
       "        INT checked_by FK            \n",
       "        BOOLEAN is_final_decision    \n",
       "        TEXT decision_comment\n",
       "    }\n",
       "\n",
       "    AUDIT_LOGS {\n",
       "        INT id PK\n",
       "        INT user_id FK\n",
       "        UUID document_id FK\n",
       "        VARCHAR action\n",
       "        VARCHAR entity_type\n",
       "        INT entity_id\n",
       "        JSONB changes\n",
       "        DATETIME timestamp\n",
       "        VARCHAR ip_address\n",
       "    }\n",
       "\n",
       "    %% Relations façon Workbench\n",
       "    ROLES ||--o{ USERS : \"role_id\"\n",
       "    USERS ||--o{ RULE_CONFIGS : \"created_by\"\n",
       "    USERS ||--o{ AUDIT_LOGS : \"user_id\"\n",
       "\n",
       "    DOMAINS ||--o{ RULE_CONFIGS : \"domain_id\"\n",
       "\n",
       "    %% Domaine -> APIs (plusieurs APIs dans le même domaine)\n",
       "    DOMAINS ||--o{ APIS : \"domain_id\"\n",
       "    RULE_CONFIGS ||--o{ APIS : \"rule_config_id\"\n",
       "    USERS ||--o{ APIS : \"created_by\"\n",
       "\n",
       "    %% API -> API_KEYS (plusieurs clés par API)\n",
       "    APIS ||--o{ API_KEYS : \"api_id\"\n",
       "\n",
       "    %% Domaine -> Documents\n",
       "    DOMAINS ||--o{ DOCUMENTS : \"domain_id\"\n",
       "    USERS ||--o{ DOCUMENTS : \"uploaded_by\"\n",
       "    APIS ||--o{ DOCUMENTS : \"api_id\"\n",
       "\n",
       "    %% Documents -> stockage + extractions + quality\n",
       "    DOCUMENTS ||--|| FILE_STORAGE : \"document_id\"\n",
       "    DOCUMENTS ||--o{ EXTRACTIONS : \"document_id\"\n",
       "    RULE_CONFIGS ||--o{ EXTRACTIONS : \"rule_config_id\"\n",
       "    USERS ||--o{ EXTRACTIONS : \"overridden_by\"\n",
       "\n",
       "    DOCUMENTS ||--o{ QUALITY_GATE_LOGS : \"document_id\"\n",
       "    USERS ||--o{ QUALITY_GATE_LOGS : \"checked_by\"\n",
       "\n",
       "    DOCUMENTS ||--o{ AUDIT_LOGS : \"document_id\"\n",
       "</div>\n",
       "\n",
       "<script type=\"module\">\n",
       "  const render = async () => {\n",
       "    if (!window.__mermaid_loaded__) {\n",
       "      const mermaid = (await import(\"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs\")).default;\n",
       "      window.mermaid = mermaid;\n",
       "      window.__mermaid_loaded__ = true;\n",
       "      mermaid.initialize({\n",
       "        startOnLoad: false,\n",
       "        securityLevel: \"loose\"\n",
       "      });\n",
       "    }\n",
       "    await window.mermaid.run({\n",
       "      nodes: [document.getElementById(\"mmd-87e775658fb348b8a74d39591f97caae\")]\n",
       "    });\n",
       "  };\n",
       "  render();\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import re, json, uuid\n",
    "\n",
    "raw = r\"\"\"\n",
    "---\n",
    "config:\n",
    "  layout: elk\n",
    "  theme: redux-dark-color\n",
    "---\n",
    "\n",
    "erDiagram\n",
    "    ROLES {\n",
    "        INT id PK\n",
    "        VARCHAR name\n",
    "    }\n",
    "\n",
    "    USERS {\n",
    "        INT id PK\n",
    "        VARCHAR username\n",
    "        VARCHAR email\n",
    "        VARCHAR password_hash\n",
    "        INT role_id FK\n",
    "        DATETIME created_at\n",
    "    }\n",
    "\n",
    "    DOMAINS {\n",
    "        INT id PK\n",
    "        VARCHAR name\n",
    "    }\n",
    "\n",
    "    RULE_CONFIGS {\n",
    "        INT id PK\n",
    "        INT domain_id FK\n",
    "        VARCHAR version_label_Regex\n",
    "        JSONB Regex_json\n",
    "        INT created_by FK\n",
    "        DATETIME created_at\n",
    "        BOOLEAN is_active\n",
    "    }\n",
    "\n",
    "    %% Nouvelle table: \"API\" = profil/config par domaine (langue, règles, paramètres)\n",
    "    APIS {\n",
    "        INT id PK\n",
    "        INT domain_id FK\n",
    "        INT rule_config_id FK\n",
    "        VARCHAR name\n",
    "        VARCHAR language_code          \n",
    "        JSONB settings_json           \n",
    "        BOOLEAN is_active\n",
    "        INT created_by FK\n",
    "        DATETIME created_at\n",
    "    }\n",
    "\n",
    "    %% Clés par API (une API/profil peut avoir plusieurs clés d'accès)\n",
    "    API_KEYS {\n",
    "        INT id PK\n",
    "        INT api_id FK\n",
    "        VARCHAR key_hash              \n",
    "        JSONB scopes                  \n",
    "        DATETIME created_at\n",
    "        DATETIME last_used_at\n",
    "        DATETIME expires_at\n",
    "        DATETIME revoked_at\n",
    "    }\n",
    "\n",
    "    DOCUMENTS {\n",
    "        UUID id PK\n",
    "        VARCHAR filename\n",
    "        INT domain_id FK\n",
    "        VARCHAR status\n",
    "        VARCHAR empreinte_numerique\n",
    "        DATETIME uploaded_at\n",
    "        INT uploaded_by FK\n",
    "        INT api_id FK                 \n",
    "    }\n",
    "\n",
    "    FILE_STORAGE {\n",
    "        INT id PK\n",
    "        UUID document_id FK\n",
    "        VARCHAR object_path\n",
    "        INT size\n",
    "        VARCHAR empreinte_numerique\n",
    "        DATETIME stored_at\n",
    "    }\n",
    "\n",
    "    EXTRACTIONS {\n",
    "        INT id PK\n",
    "        UUID document_id FK\n",
    "        INT rule_config_id FK\n",
    "        VARCHAR field_name\n",
    "        TEXT extracted_value\n",
    "        JSONB coordinates\n",
    "        BOOLEAN is_valid\n",
    "        BOOLEAN is_overridden\n",
    "        INT overridden_by FK\n",
    "        DATETIME overridden_at\n",
    "    }\n",
    "\n",
    "    QUALITY_GATE_LOGS {\n",
    "        INT id PK\n",
    "        UUID document_id FK\n",
    "        BOOLEAN is_passed\n",
    "        TEXT failure_reason\n",
    "        DATETIME checked_at\n",
    "        VARCHAR check_origin          \n",
    "        INT checked_by FK            \n",
    "        BOOLEAN is_final_decision    \n",
    "        TEXT decision_comment\n",
    "    }\n",
    "\n",
    "    AUDIT_LOGS {\n",
    "        INT id PK\n",
    "        INT user_id FK\n",
    "        UUID document_id FK\n",
    "        VARCHAR action\n",
    "        VARCHAR entity_type\n",
    "        INT entity_id\n",
    "        JSONB changes\n",
    "        DATETIME timestamp\n",
    "        VARCHAR ip_address\n",
    "    }\n",
    "\n",
    "    %% Relations façon Workbench\n",
    "    ROLES ||--o{ USERS : \"role_id\"\n",
    "    USERS ||--o{ RULE_CONFIGS : \"created_by\"\n",
    "    USERS ||--o{ AUDIT_LOGS : \"user_id\"\n",
    "\n",
    "    DOMAINS ||--o{ RULE_CONFIGS : \"domain_id\"\n",
    "\n",
    "    %% Domaine -> APIs (plusieurs APIs dans le même domaine)\n",
    "    DOMAINS ||--o{ APIS : \"domain_id\"\n",
    "    RULE_CONFIGS ||--o{ APIS : \"rule_config_id\"\n",
    "    USERS ||--o{ APIS : \"created_by\"\n",
    "\n",
    "    %% API -> API_KEYS (plusieurs clés par API)\n",
    "    APIS ||--o{ API_KEYS : \"api_id\"\n",
    "\n",
    "    %% Domaine -> Documents\n",
    "    DOMAINS ||--o{ DOCUMENTS : \"domain_id\"\n",
    "    USERS ||--o{ DOCUMENTS : \"uploaded_by\"\n",
    "    APIS ||--o{ DOCUMENTS : \"api_id\"\n",
    "\n",
    "    %% Documents -> stockage + extractions + quality\n",
    "    DOCUMENTS ||--|| FILE_STORAGE : \"document_id\"\n",
    "    DOCUMENTS ||--o{ EXTRACTIONS : \"document_id\"\n",
    "    RULE_CONFIGS ||--o{ EXTRACTIONS : \"rule_config_id\"\n",
    "    USERS ||--o{ EXTRACTIONS : \"overridden_by\"\n",
    "\n",
    "    DOCUMENTS ||--o{ QUALITY_GATE_LOGS : \"document_id\"\n",
    "    USERS ||--o{ QUALITY_GATE_LOGS : \"checked_by\"\n",
    "\n",
    "    DOCUMENTS ||--o{ AUDIT_LOGS : \"document_id\"\n",
    "\"\"\"\n",
    "\n",
    "def extract_front_matter(mermaid_text: str):\n",
    "    s = mermaid_text.strip(\"\\n\")\n",
    "    if not s.lstrip().startswith(\"---\"):\n",
    "        return {}, s\n",
    "\n",
    "    m = re.match(r\"^\\s*---\\s*(.*?)\\s*---\\s*(.*)$\", s, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        return {}, s\n",
    "\n",
    "    front = m.group(1)\n",
    "    body = m.group(2)\n",
    "\n",
    "    theme = None\n",
    "    layout = None\n",
    "    for line in front.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"theme:\"):\n",
    "            theme = line.split(\":\", 1)[1].strip()\n",
    "        if line.startswith(\"layout:\"):\n",
    "            layout = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "    init = {}\n",
    "    if theme:\n",
    "        init[\"theme\"] = theme\n",
    "    if layout:\n",
    "        init[\"layout\"] = layout\n",
    "\n",
    "    return init, body.strip(\"\\n\")\n",
    "\n",
    "init_cfg, diagram = extract_front_matter(raw)\n",
    "\n",
    "init_directive = \"\"\n",
    "if init_cfg:\n",
    "    init_directive = f\"%%{{init: {json.dumps(init_cfg)} }}%%\\n\"\n",
    "\n",
    "diagram_final = init_directive + diagram\n",
    "div_id = f\"mmd-{uuid.uuid4().hex}\"\n",
    "\n",
    "html = f\"\"\"\n",
    "<div id=\"{div_id}\" class=\"mermaid\">\n",
    "{diagram_final}\n",
    "</div>\n",
    "\n",
    "<script type=\"module\">\n",
    "  const render = async () => {{\n",
    "    if (!window.__mermaid_loaded__) {{\n",
    "      const mermaid = (await import(\"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs\")).default;\n",
    "      window.mermaid = mermaid;\n",
    "      window.__mermaid_loaded__ = true;\n",
    "      mermaid.initialize({{\n",
    "        startOnLoad: false,\n",
    "        securityLevel: \"loose\"\n",
    "      }});\n",
    "    }}\n",
    "    await window.mermaid.run({{\n",
    "      nodes: [document.getElementById(\"{div_id}\")]\n",
    "    }});\n",
    "  }};\n",
    "  render();\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f87e0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
